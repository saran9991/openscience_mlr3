#Section 1 : In this section, we first install all the necessary libraries, import them, set the tasks and define configurations related to the AutoTuner class
install.packages(c('mlr3','mlr3verse', 'mlr3learners', 'paradox', 'mlr3tuning', 'mlr3pipelines', 'mlr3viz', 'mlr3tuningspaces', 'mlr3oml', 'ggplot2', 'dplyr', 'gridExtra', 'igraph', 'ranger', 'xgboost', 'R6'))
library(mlr3)
library(mlr3verse)
library(mlr3learners)
library(paradox)
library(mlr3tuning)
library(mlr3pipelines)
library(mlr3viz)
library(mlr3tuningspaces)
library(mlr3oml)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(igraph)
library(ranger)
library(xgboost)
library(R6)
#We first set a seed to ensure reproducibility
set.seed(1)
tasks = list( tsk('pima') , tsk('sonar'), tsk("oml", task_id = 10093), tsk('oml', task_id=10101) , tsk('oml', task_id= 15))
# Tasks breakdown:
# Task:             'pima'      -       Pima Indians Diabetes Dataset              https://www.openml.org/search?type=data&status=active&id=37
# Task:             'sonar'     -       Sonar Dataset                              https://www.openml.org/search?type=data&status=active&id=40
# Task with ID:     '10093'     -       Banknote Authentication Dataset            https://www.openml.org/search?type=data&status=active&id=1462
# Task with ID:     '10101'     -       Blood Transfusion Service Center Dataset   https://www.openml.org/search?type=data&status=active&id=1464
# Task with ID:     '15'        -       Breast Cancer Wisconsin Dataset            https://www.openml.org/search?type=data&status=active&id=15
rand_tuner = tnr("random_search")         # Defining that the Tuner should be Random Search Tuner | Can be - Bayesian Optimization (mbo), Grid Search (grid_search) etc
terminator = trm("run_time", secs = 15)   # Termination Criteria : Hyperparamter Search ends after 15 seconds, can be decreased to reduce the searching time but may affect classfication accuracy
rsmp_tuner = rsmp("cv", folds = 3)        # Resampling that is used to evaluate the performance of the hyperparameter configurations
# Section 2: In this section, we define the learners (classifiers), the hyperparameter search space for different learners and benchmark the performance of the learners on the above tasks (datasets) with respect to different evaluation measures
# Using mlr3pipelines, learner pipelines are created that include mean imputation and scaling preprocessing operators (PipeOps)
# Baseline Classifier - A featureless classifier which makes random guesses for the correct class
featureless_lrn = lrn('classif.featureless', predict_type = 'prob')
featureless_lrn = po('imputemean') %>>%  po('scale')  %>>%  featureless_lrn         # Joining the featureless learner with 2 preprocessing operators using %>>% (PipeOps join operator)
plot(featureless_lrn, html=FALSE)
# Random Forest Classfier with defined parameter search space (mtry.ratio and num.trees chosen to be tuned)
ranger_lrn = lrn("classif.ranger", mtry.ratio = to_tune(0.5,1), num.trees = to_tune(100,128), predict_type = "prob")
